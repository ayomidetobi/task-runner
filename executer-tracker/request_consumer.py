import os
import shutil
import zipfile
from absl import logging

from utils import make_task_key
from subprocess_tracker import SubprocessTracker


class RequestConsumer:
    def __init__(self, redis_connection, working_dir_root, artifact_dest):
        self.redis = redis_connection
        self.working_dir_root = working_dir_root
        self.artifact_dest = artifact_dest

    def __call__(self, request):
        task_id = request["id"]

        # This just checks the request status.
        # If it is different than submitted,
        # it means it has already been processed.
        # Right now, this avoids processing the same request twice
        request_status = self.redis.get(
            make_task_key(task_id, "status"))
        logging.info("Status of request %s: %s", task_id,
                        request_status)

        if request_status != "submitted":
            return

        # Create working dir for the script that will accomplish
        # the received request
        # The uniqueness of the working dir is guaranteed
        # by using the ID generated by Redis
        working_dir = os.path.join(self.working_dir_root, task_id)
        os.makedirs(working_dir, exist_ok=True)

        # If "params" is not in the request, it means
        # that the input is a zip file
        if "params" not in request:
            input_zip_path = os.path.join(self.artifact_dest, task_id,
                                            "input.zip")

            # Extract files to the working_dir
            # NOTE: it is expected that the input.json is
            # inside the zip file
            with zipfile.ZipFile(input_zip_path, "r") as zip_fp:
                zip_fp.extractall(working_dir)

            logging.info("Extracted input zip %s to %s", input_zip_path,
                            working_dir)
        else:
            # Create input json file
            os.makedirs(working_dir)

            input_json_path = os.path.join(working_dir, "input.json")
            with open(input_json_path, "w", encoding="UTF-8") as fp:
                fp.write(request["params"])

        method_name = request["method"].split(".")[-1]
        method_path = os.path.join("/scripts", f"{method_name}.py")
        command_line = f"python {method_path}"

        tracker = SubprocessTracker(
            working_dir=working_dir,
            command_line=command_line,
        )

        # Mark task as started
        self.redis.set(make_task_key(task_id, "status"),
                                "started")
        exit_code = tracker.run()

        logging.info("Tracker returned exit code %s", str(exit_code))

        # Compress outputs, storing them in the shared drive
        output_dir = os.path.join(working_dir, "output")
        output_zip_name = os.path.join(self.artifact_dest, task_id,
                                        "output")

        output_zip_path = shutil.make_archive(output_zip_name, "zip",
                                                output_dir)

        logging.info("Compressed output to %s", output_zip_path)

        # Assuming everything ran successfully for now

        # Mark task as finished successfully
        out = self.redis.set(make_task_key(task_id, "status"),
                                    "success")
        logging.info("Marking task as successful: %s", out)
